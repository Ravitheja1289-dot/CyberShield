{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unfortunately, credit card fraud occurs everyday all over the world. However, credit card companies have made significant progress in detecting these occurences in order to protect their customers. This dataset contains credit card transactions made in September 2013 in Europe over two days.\n",
    "\n",
    "#### The goal of this notebook is to detect fraud and predict when they could occur. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 2. Importing Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:19.204933Z",
     "start_time": "2024-12-12T21:25:18.947671Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:23.347905Z",
     "start_time": "2024-12-12T21:25:19.206035Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train_original = pd.read_csv(r\"spam_dataset.csv\")\n",
    "\n",
    "df_train_original.drop(df_train_original.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_test_original = pd.read_csv(r\"spam_dataset.csv\")\n",
    "\n",
    "df_test_original.drop(df_test_original.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# In order to seperate test and training subsets later on in the notebook\n",
    "df_original = pd.concat([df_train_original,df_test_original], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:23.788939Z",
     "start_time": "2024-12-12T21:25:23.351333Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the proportion of the sample size we want\n",
    "sample_size = 0.15  \n",
    "\n",
    "# Performing stratified sampling\n",
    "df, _ = train_test_split(df_train_original, test_size=1-sample_size, random_state=42)\n",
    "\n",
    "# Displaying the sampled DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Data Description\n",
    "#### We'll first create a custom function that shows us the data type, % missing data, and number of unique values for each feature in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:24.051882Z",
     "start_time": "2024-12-12T21:25:23.790976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def df_explore(df):\n",
    "    missing = pd.DataFrame((df.isna().sum()/df.shape[0])*100).reset_index().rename(columns={'index': 'column',0:'%_missing'}).sort_values(by = '%_missing',ascending=False)\n",
    "    nunique = pd.DataFrame(df.nunique()).reset_index().rename(columns={'index': 'column',0:'nunique'}).sort_values(by = 'nunique',ascending=False)\n",
    "    dtypes = pd.DataFrame(df.dtypes).reset_index().rename(columns={'index': 'column',0:'dtype'})\n",
    "    return pd.merge(pd.merge(dtypes,missing,on='column'),nunique,on='column',how='left').sort_values(by='%_missing',ascending=False).sort_values(by = 'nunique', ascending = False)\n",
    "print(df.shape)\n",
    "\n",
    "df_explore(df).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Data Balance Check\n",
    "#### When dealing with binary target features, it's always good to determine if the data is balanced or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:24.143553Z",
     "start_time": "2024-12-12T21:25:24.052612Z"
    }
   },
   "outputs": [],
   "source": [
    "df['is_spam'] = df['is_spam'].apply(lambda x: \"Fraud\" if x==1 else \"No Fraud\")\n",
    "\n",
    "is_spam_values = df['is_spam'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.pie(is_spam_values, labels=is_spam_values.index, autopct='%1.1f%%', startangle=90, colors=sns.color_palette(\"deep\", n_colors=len(is_spam_values)))\n",
    "plt.title('% of Fraudulent vs Non-fraudulent emails')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that we have highly unbalanced data. This represents a severe skew in the class distribution. We have some methods to help alleviate this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Fraud by Transaction Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:24.242313Z",
     "start_time": "2024-12-12T21:25:24.144180Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(x=\"message_content\", data=df[df['is_spam']==\"Spam\"], palette=\"Set2\", hue = 'category')\n",
    "\n",
    "plt.title('Instances of Fraud by Transaction Category')\n",
    "plt.xlabel('Transaction Category')\n",
    "plt.ylabel('Count of Fraud Instance')\n",
    "plt.xticks(rotation=45, ha = 'right')\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Fraud by Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:24.330871Z",
     "start_time": "2024-12-12T21:25:24.242966Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df['is_spam']==\"Spam\"][\"message_content\"].value_counts(sort=True,ascending=False).head(10).plot(kind=\"bar\",x='message_content', y=df['is_spam']==\"Spam\", color=['red', 'green', 'blue', 'orange', 'purple'])\n",
    "plt.title(\"Top of Credit Card Frauds by Job\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.1  Dropping duplicated values\n",
    "#### A first simple step in cleaning the dataset is to remove any duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:24.588859Z",
     "start_time": "2024-12-12T21:25:24.331835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "\n",
    "df2.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\"Duplicated values dropped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.2 Transforming Variables\n",
    "#### Here we will check whether any variables can be easily transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming the gender variable to be binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:24.620967Z",
     "start_time": "2024-12-12T21:25:24.589701Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def gender_transform(x):\n",
    "    if x=='1':\n",
    "        return 1\n",
    "    if x=='0':\n",
    "        return 0\n",
    "df2['is_fraud'] = df2['is_fraud'].transform(gender_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Dummy Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuing to process our data for a models, we'll take a look at the categorical data and their number of unique values to determine which we should retain for dummy variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:24.627435Z",
     "start_time": "2024-12-12T21:25:24.623253Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df3 = df2.drop(['is_spam'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:24.665225Z",
     "start_time": "2024-12-12T21:25:24.627960Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Ensure there are string columns to encode\n",
    "string_cols = df3.select_dtypes('object')\n",
    "\n",
    "if not string_cols.empty:\n",
    "    df3_dummies = pd.get_dummies(string_cols)  # Remove dtype=int\n",
    "    df4 = pd.concat([df3.drop(string_cols.columns, axis=1), df3_dummies], axis=1)\n",
    "else:\n",
    "    df4 = df3.copy()  # No categorical columns to encode\n",
    "\n",
    "print(df4.shape)\n",
    "print(df4.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Stratified Train/Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to generate a training / validation dataset split that will keep the same percentages of classes in each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df4.columns)  # Check if 'is_spam' is present\n",
    "df4 = df4.reset_index(drop=True)  # `drop` should be True, not 'index'\n",
    "df4.columns = df4.columns.str.strip()  # Removes leading/trailing spaces\n",
    "\n",
    "X = df4.drop(columns=['is_spam'], errors='ignore')  # Ignores missing columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.reset_index(drop=True)  # Fix reset_index()\n",
    "\n",
    "print(df4.columns)  # Debugging step to check column names\n",
    "\n",
    "if 'is_spam' in df4.columns:\n",
    "    X = df4.drop('is_spam', axis=1)\n",
    "    y = df4['is_spam']\n",
    "else:\n",
    "    print(\"Column 'is_spam' not found in df4\")\n",
    "\n",
    "if 'message_content' in df4.columns:\n",
    "    y = df4['message_content']\n",
    "else:\n",
    "    print(\"Column 'message_content' not found in df4\")\n",
    "\n",
    "# Proceed only if both columns exist\n",
    "if 'is_spam' in df4.columns and 'message_content' in df4.columns:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:24.751070Z",
     "start_time": "2024-12-12T21:25:24.665776Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X = df4.reset_index(drop='index').drop('is_fraud', axis=1)\n",
    "\n",
    "y = df4.reset_index(drop='index')['is_fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:24.756704Z",
     "start_time": "2024-12-12T21:25:24.752195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Creating a function for scaling\n",
    "\n",
    "def Standard_Scaler (df, col_names):\n",
    "\n",
    "    features = df[col_names]\n",
    "\n",
    "    scaler = StandardScaler().fit(features.values)\n",
    "\n",
    "    features = scaler.transform(features.values)\n",
    "\n",
    "    df[col_names] = features\n",
    "\n",
    "    return df\n",
    "\n",
    "col_names = ['amt']\n",
    "\n",
    "X_train = Standard_Scaler (X_train, col_names)\n",
    "\n",
    "X_test = Standard_Scaler (X_test, col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Baseline Model (no imbalance resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll start with building a baseline random forest model so we can have a reference in how the model performs if we left the data as is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Instantiating the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:24.759208Z",
     "start_time": "2024-12-12T21:25:24.757355Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:45.625780Z",
     "start_time": "2024-12-12T21:25:24.759859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "y_pred_baseline = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 Performance and Accuracy Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:45.642199Z",
     "start_time": "2024-12-12T21:25:45.626557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Performance with imbalanced dataset:\")\n",
    "print(classification_report(y_test, y_pred_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:45.659936Z",
     "start_time": "2024-12-12T21:25:45.643238Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_baseline)\n",
    "\n",
    "rf_baseline_Recall = recall_score(y_test, y_pred_baseline)\n",
    "rf_baseline_Precision = precision_score(y_test, y_pred_baseline)\n",
    "rf_baseline_f1 = f1_score(y_test, y_pred_baseline)\n",
    "rf_baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
    "\n",
    "ndf = [(rf_baseline_Recall, rf_baseline_Precision, rf_baseline_f1, rf_baseline_accuracy)]\n",
    "\n",
    "rf_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
    "rf_score.insert(0, 'Random Forest performed with', 'Original (Imbalanced Dataset)')\n",
    "rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Random Resampling Methods for Imbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Random Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 Instantiating the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:45.766852Z",
     "start_time": "2024-12-12T21:25:45.660599Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# defining oversampling method\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "rf_oversample = RandomForestClassifier(n_estimators=200)\n",
    "X_train_oversample, y_train_oversample = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:15.341971Z",
     "start_time": "2024-12-12T21:25:45.767677Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_oversample.fit(X_train_oversample, y_train_oversample)\n",
    "y_pred_oversample = rf_oversample.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 Performance and Accuracy Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:15.356519Z",
     "start_time": "2024-12-12T21:26:15.343009Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Performance with Random Oversampling:\")\n",
    "print(classification_report(y_test, y_pred_oversample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:15.375293Z",
     "start_time": "2024-12-12T21:26:15.357072Z"
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_oversample)\n",
    "\n",
    "oversample_rf_Recall = recall_score(y_test, y_pred_oversample)\n",
    "oversample_rf_Precision = precision_score(y_test, y_pred_oversample)\n",
    "oversample_rf_f1 = f1_score(y_test, y_pred_oversample)\n",
    "oversample_rf_accuracy = accuracy_score(y_test, y_pred_oversample)\n",
    "\n",
    "ndf_over = [(oversample_rf_Recall, oversample_rf_Precision, oversample_rf_f1, oversample_rf_accuracy)]\n",
    "\n",
    "oversample_rf_score = pd.DataFrame(data = ndf_over, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
    "oversample_rf_score.insert(0, 'Random Forest performed with', 'Random Oversampling')\n",
    "oversample_rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Random Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Instantiate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:15.388770Z",
     "start_time": "2024-12-12T21:26:15.375981Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# defining oversampling method\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "rf_undersample = RandomForestClassifier(n_estimators=200)\n",
    "X_train_undersample, y_train_undersample = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:16.154974Z",
     "start_time": "2024-12-12T21:26:15.389708Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rf_undersample.fit(X_train_undersample, y_train_undersample)\n",
    "y_pred_undersample = rf_undersample.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 Performance and Accuracy Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:16.176689Z",
     "start_time": "2024-12-12T21:26:16.156531Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Performance with Random Undersampling:\")\n",
    "print(classification_report(y_test, y_pred_undersample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:16.194189Z",
     "start_time": "2024-12-12T21:26:16.177363Z"
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_undersample)\n",
    "\n",
    "undersample_rf_Recall = recall_score(y_test, y_pred_undersample)\n",
    "undersample_rf_Precision = precision_score(y_test, y_pred_undersample)\n",
    "undersample_rf_f1 = f1_score(y_test, y_pred_undersample)\n",
    "undersample_rf_accuracy = accuracy_score(y_test, y_pred_undersample)\n",
    "\n",
    "ndf_over = [(undersample_rf_Recall, undersample_rf_Precision, undersample_rf_f1, undersample_rf_accuracy)]\n",
    "\n",
    "undersample_rf_score = pd.DataFrame(data = ndf_over, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
    "undersample_rf_score.insert(0, 'Random Forest performed with', 'Random Undersampling')\n",
    "undersample_rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 SMOTE (Synthetic Minority Oversampling Technique)¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 Instantiate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:16.341942Z",
     "start_time": "2024-12-12T21:26:16.194916Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "rf_smote = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:26.757324Z",
     "start_time": "2024-12-12T21:26:16.343287Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_smote.fit(X_train_smote,y_train_smote)\n",
    "y_pred_smote = rf_smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.3 Performance and Accuracy Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:26.773978Z",
     "start_time": "2024-12-12T21:26:26.761239Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Performance with SMOTE:\")\n",
    "print(classification_report(y_test, y_pred_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:26.788407Z",
     "start_time": "2024-12-12T21:26:26.774566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cm_smote = confusion_matrix(y_test, y_pred_smote)\n",
    "rf_smote_Recall = recall_score(y_test, y_pred_smote)\n",
    "rf_smote_Precision = precision_score(y_test, y_pred_smote)\n",
    "rf_smote_f1 = f1_score(y_test, y_pred_smote)\n",
    "rf_smote_accuracy = accuracy_score(y_test, y_pred_smote)\n",
    "\n",
    "ndf = [(rf_smote_Recall, rf_smote_Precision, rf_smote_f1, rf_smote_accuracy)]\n",
    "\n",
    "rf_smote_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
    "rf_smote_score.insert(0, 'Random Forest performed with', 'Smote Oversampling')\n",
    "rf_smote_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Tomek & SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1 Instantiate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:49.009287Z",
     "start_time": "2024-12-12T21:26:26.789055Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "SMOTETomek = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'))\n",
    "rf_SMOTETomek = RandomForestClassifier(n_estimators=200)\n",
    "X_train_SMOTETomek, y_train_SMOTETomek = SMOTETomek.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.2 Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:27:54.829740Z",
     "start_time": "2024-12-12T21:26:49.010040Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_SMOTETomek.fit(X_train_SMOTETomek,y_train_SMOTETomek)\n",
    "y_pred_SMOTETomek = rf_SMOTETomek.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.3 Performance and Accuracy Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:27:54.843264Z",
     "start_time": "2024-12-12T21:27:54.830616Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Performance with SMOTE:\")\n",
    "print(classification_report(y_test, y_pred_SMOTETomek))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:27:54.857897Z",
     "start_time": "2024-12-12T21:27:54.843838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cm_smote_tomek = confusion_matrix(y_test, y_pred_SMOTETomek)\n",
    "rf_smote_tomek_Recall = recall_score(y_test, y_pred_SMOTETomek)\n",
    "rf_smote_tomek_Precision = precision_score(y_test, y_pred_SMOTETomek)\n",
    "rf_smote_tomek_f1 = f1_score(y_test, y_pred_SMOTETomek)\n",
    "rf_smote_tomek_accuracy = accuracy_score(y_test, y_pred_SMOTETomek)\n",
    "\n",
    "ndf = [(rf_smote_tomek_Recall, rf_smote_tomek_Precision, rf_smote_tomek_f1, rf_smote_tomek_accuracy)]\n",
    "\n",
    "rf_smote_tomek_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
    "rf_smote_tomek_score.insert(0, 'Random Forest performed with', 'SMOTE & Tomek')\n",
    "rf_smote_tomek_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:27:54.861953Z",
     "start_time": "2024-12-12T21:27:54.858452Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rf_sampling_scores = pd.concat([rf_score, oversample_rf_score, undersample_rf_score,rf_smote_score, rf_smote_tomek_score],axis = 0)\n",
    "rf_sampling_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Applying best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.1 Showing the accuracy score again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:27:54.865136Z",
     "start_time": "2024-12-12T21:27:54.862508Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_undersample)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.2 Print the predicted and actual class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:27:54.873951Z",
     "start_time": "2024-12-12T21:27:54.865686Z"
    }
   },
   "outputs": [],
   "source": [
    "# remapping the classes \n",
    "class_names = {1:'Fraud',0:'No Fraud'}\n",
    "predicted_classes = [class_names[label] for label in y_pred_undersample]\n",
    "\n",
    "# Mapping true labels to custom class names\n",
    "class_map = [class_names[label] for label in y_test]\n",
    "\n",
    "# Step 10: Print the predicted and actual class names for the first 5 test samples\n",
    "for i in range(20):\n",
    "    print(f\"Sample {i+1}: True Class: {class_map[i]}, Predicted Class: {predicted_classes[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 817870,
     "sourceId": 1399887,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30806,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
