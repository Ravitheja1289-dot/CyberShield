{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:19.204933Z",
     "start_time": "2024-12-12T21:25:18.947671Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:23.347905Z",
     "start_time": "2024-12-12T21:25:19.206035Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ravit\\AppData\\Local\\Temp\\ipykernel_8892\\165452562.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train_original = pd.read_csv(r\"spam_dataset.csv\")\n",
      "C:\\Users\\ravit\\AppData\\Local\\Temp\\ipykernel_8892\\165452562.py:5: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_test_original = pd.read_csv(r\"spam_dataset.csv\")\n"
     ]
    }
   ],
   "source": [
    "df_train_original = pd.read_csv(r\"spam_dataset.csv\")\n",
    "\n",
    "df_train_original.drop(df_train_original.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_test_original = pd.read_csv(r\"spam_dataset.csv\")\n",
    "\n",
    "df_test_original.drop(df_test_original.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# In order to seperate test and training subsets later on in the notebook\n",
    "df_original = pd.concat([df_train_original,df_test_original], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:23.788939Z",
     "start_time": "2024-12-12T21:25:23.351333Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83357, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the proportion of the sample size we want\n",
    "sample_size = 0.15  \n",
    "\n",
    "# Performing stratified sampling\n",
    "df, _ = train_test_split(df_train_original, test_size=1-sample_size, random_state=42)\n",
    "\n",
    "# Displaying the sampled DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:24.051882Z",
     "start_time": "2024-12-12T21:25:23.790976Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83357, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>%_missing</th>\n",
       "      <th>nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is_spam</td>\n",
       "      <td>float64</td>\n",
       "      <td>99.803256</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is_fraud</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     column    dtype  %_missing  nunique\n",
       "0   is_spam  float64  99.803256        2\n",
       "1  is_fraud    int64   0.000000        2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_explore(df):\n",
    "    missing = pd.DataFrame((df.isna().sum()/df.shape[0])*100).reset_index().rename(columns={'index': 'column',0:'%_missing'}).sort_values(by = '%_missing',ascending=False)\n",
    "    nunique = pd.DataFrame(df.nunique()).reset_index().rename(columns={'index': 'column',0:'nunique'}).sort_values(by = 'nunique',ascending=False)\n",
    "    dtypes = pd.DataFrame(df.dtypes).reset_index().rename(columns={'index': 'column',0:'dtype'})\n",
    "    return pd.merge(pd.merge(dtypes,missing,on='column'),nunique,on='column',how='left').sort_values(by='%_missing',ascending=False).sort_values(by = 'nunique', ascending = False)\n",
    "print(df.shape)\n",
    "\n",
    "df_explore(df).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:24.242313Z",
     "start_time": "2024-12-12T21:25:24.144180Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `message_content` for `x`. An entry with this name does not appear in `data`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sns\u001b[38;5;241m.\u001b[39mcountplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage_content\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m=\u001b[39mdf[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_spam\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpam\u001b[39m\u001b[38;5;124m\"\u001b[39m], palette\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSet2\u001b[39m\u001b[38;5;124m\"\u001b[39m, hue \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstances of Fraud by Transaction Category\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransaction Category\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ravit\\anaconda3\\Lib\\site-packages\\seaborn\\categorical.py:2631\u001b[0m, in \u001b[0;36mcountplot\u001b[1;34m(data, x, y, hue, order, hue_order, orient, color, palette, saturation, fill, hue_norm, stat, width, dodge, gap, log_scale, native_scale, formatter, legend, ax, **kwargs)\u001b[0m\n\u001b[0;32m   2628\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2629\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot pass values for both `x` and `y`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2631\u001b[0m p \u001b[38;5;241m=\u001b[39m _CategoricalAggPlotter(\n\u001b[0;32m   2632\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m   2633\u001b[0m     variables\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(x\u001b[38;5;241m=\u001b[39mx, y\u001b[38;5;241m=\u001b[39my, hue\u001b[38;5;241m=\u001b[39mhue),\n\u001b[0;32m   2634\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   2635\u001b[0m     orient\u001b[38;5;241m=\u001b[39morient,\n\u001b[0;32m   2636\u001b[0m     color\u001b[38;5;241m=\u001b[39mcolor,\n\u001b[0;32m   2637\u001b[0m     legend\u001b[38;5;241m=\u001b[39mlegend,\n\u001b[0;32m   2638\u001b[0m )\n\u001b[0;32m   2640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2641\u001b[0m     ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mgca()\n",
      "File \u001b[1;32mc:\\Users\\ravit\\anaconda3\\Lib\\site-packages\\seaborn\\categorical.py:67\u001b[0m, in \u001b[0;36m_CategoricalPlotter.__init__\u001b[1;34m(self, data, variables, order, orient, require_numeric, color, legend)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     58\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     legend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     65\u001b[0m ):\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(data\u001b[38;5;241m=\u001b[39mdata, variables\u001b[38;5;241m=\u001b[39mvariables)\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# This method takes care of some bookkeeping that is necessary because the\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# original categorical plots (prior to the 2021 refactor) had some rules that\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# don't fit exactly into VectorPlotter logic. It may be wise to have a second\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# default VectorPlotter rules. If we do decide to make orient part of the\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# _base variable assignment, we'll want to figure out how to express that.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwide\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\ravit\\anaconda3\\Lib\\site-packages\\seaborn\\_base.py:634\u001b[0m, in \u001b[0;36mVectorPlotter.__init__\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;66;03m# var_ordered is relevant only for categorical axis variables, and may\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;66;03m# be better handled by an internal axis information object that tracks\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# such information and is set up by the scale_* methods. The analogous\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# information for numeric axes would be information about log scales.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_ordered \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}  \u001b[38;5;66;03m# alt., used DefaultDict\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign_variables(data, variables)\n\u001b[0;32m    636\u001b[0m \u001b[38;5;66;03m# TODO Lots of tests assume that these are called to initialize the\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;66;03m# mappings to default values on class initialization. I'd prefer to\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;66;03m# move away from that and only have a mapping when explicitly called.\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyle\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\ravit\\anaconda3\\Lib\\site-packages\\seaborn\\_base.py:679\u001b[0m, in \u001b[0;36mVectorPlotter.assign_variables\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;66;03m# When dealing with long-form input, use the newer PlotData\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;66;03m# object (internal but introduced for the objects interface)\u001b[39;00m\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;66;03m# to centralize / standardize data consumption logic.\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 679\u001b[0m     plot_data \u001b[38;5;241m=\u001b[39m PlotData(data, variables)\n\u001b[0;32m    680\u001b[0m     frame \u001b[38;5;241m=\u001b[39m plot_data\u001b[38;5;241m.\u001b[39mframe\n\u001b[0;32m    681\u001b[0m     names \u001b[38;5;241m=\u001b[39m plot_data\u001b[38;5;241m.\u001b[39mnames\n",
      "File \u001b[1;32mc:\\Users\\ravit\\anaconda3\\Lib\\site-packages\\seaborn\\_core\\data.py:58\u001b[0m, in \u001b[0;36mPlotData.__init__\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     53\u001b[0m     data: DataSource,\n\u001b[0;32m     54\u001b[0m     variables: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, VariableSpec],\n\u001b[0;32m     55\u001b[0m ):\n\u001b[0;32m     57\u001b[0m     data \u001b[38;5;241m=\u001b[39m handle_data_source(data)\n\u001b[1;32m---> 58\u001b[0m     frame, names, ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_variables(data, variables)\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe \u001b[38;5;241m=\u001b[39m frame\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m names\n",
      "File \u001b[1;32mc:\\Users\\ravit\\anaconda3\\Lib\\site-packages\\seaborn\\_core\\data.py:232\u001b[0m, in \u001b[0;36mPlotData._assign_variables\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    231\u001b[0m         err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn entry with this name does not appear in `data`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m \n\u001b[0;32m    236\u001b[0m     \u001b[38;5;66;03m# Otherwise, assume the value somehow represents data\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# Ignore empty data structures\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(val) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret value `message_content` for `x`. An entry with this name does not appear in `data`."
     ]
    }
   ],
   "source": [
    "sns.countplot(x=\"message_content\", data=df[df['is_spam']==\"Spam\"], palette=\"Set2\", hue = 'category')\n",
    "\n",
    "plt.title('Instances of Fraud by Transaction Category')\n",
    "plt.xlabel('Transaction Category')\n",
    "plt.ylabel('Count of Fraud Instance')\n",
    "plt.xticks(rotation=45, ha = 'right')\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Fraud by Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:24.330871Z",
     "start_time": "2024-12-12T21:25:24.242966Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'message_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ravit\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'message_content'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_spam\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpam\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage_content\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts(sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m\"\u001b[39m,x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage_content\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_spam\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpam\u001b[39m\u001b[38;5;124m\"\u001b[39m, color\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpurple\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop of Credit Card Frauds by Job\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\ravit\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\ravit\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'message_content'"
     ]
    }
   ],
   "source": [
    "df[df['is_spam']==\"Spam\"][\"message_content\"].value_counts(sort=True,ascending=False).head(10).plot(kind=\"bar\",x='message_content', y=df['is_spam']==\"Spam\", color=['red', 'green', 'blue', 'orange', 'purple'])\n",
    "plt.title(\"Top of Credit Card Frauds by Job\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:24.620967Z",
     "start_time": "2024-12-12T21:25:24.589701Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def gender_transform(x):\n",
    "    if x=='1':\n",
    "        return 1\n",
    "    if x=='0':\n",
    "        return 0\n",
    "df2['is_fraud'] = df2['is_fraud'].transform(gender_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:24.665225Z",
     "start_time": "2024-12-12T21:25:24.627960Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 0)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [53326, 192590]\n"
     ]
    }
   ],
   "source": [
    "# Ensure there are string columns to encode\n",
    "string_cols = df3.select_dtypes('object')\n",
    "\n",
    "if not string_cols.empty:\n",
    "    df3_dummies = pd.get_dummies(string_cols)  # Remove dtype=int\n",
    "    df4 = pd.concat([df3.drop(string_cols.columns, axis=1), df3_dummies], axis=1)\n",
    "else:\n",
    "    df4 = df3.copy()  # No categorical columns to encode\n",
    "\n",
    "print(df4.shape)\n",
    "print(df4.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Stratified Train/Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to generate a training / validation dataset split that will keep the same percentages of classes in each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df4.columns)  # Check if 'is_spam' is present\n",
    "df4 = df4.reset_index(drop=True)  # `drop` should be True, not 'index'\n",
    "df4.columns = df4.columns.str.strip()  # Removes leading/trailing spaces\n",
    "\n",
    "X = df4.drop(columns=['is_spam'], errors='ignore')  # Ignores missing columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n",
      "Column 'is_spam' not found in df4\n",
      "Column 'message_content' not found in df4\n"
     ]
    }
   ],
   "source": [
    "df4 = df4.reset_index(drop=True)  # Fix reset_index()\n",
    "\n",
    "print(df4.columns)  # Debugging step to check column names\n",
    "\n",
    "if 'is_spam' in df4.columns:\n",
    "    X = df4.drop('is_spam', axis=1)\n",
    "    y = df4['is_spam']\n",
    "else:\n",
    "    print(\"Column 'is_spam' not found in df4\")\n",
    "\n",
    "if 'message_content' in df4.columns:\n",
    "    y = df4['message_content']\n",
    "else:\n",
    "    print(\"Column 'message_content' not found in df4\")\n",
    "\n",
    "# Proceed only if both columns exist\n",
    "if 'is_spam' in df4.columns and 'message_content' in df4.columns:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:24.751070Z",
     "start_time": "2024-12-12T21:25:24.665776Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X = df4.reset_index(drop='index').drop('is_fraud', axis=1)\n",
    "\n",
    "y = df4.reset_index(drop='index')['is_fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:24.756704Z",
     "start_time": "2024-12-12T21:25:24.752195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Creating a function for scaling\n",
    "\n",
    "def Standard_Scaler (df, col_names):\n",
    "\n",
    "    features = df[col_names]\n",
    "\n",
    "    scaler = StandardScaler().fit(features.values)\n",
    "\n",
    "    features = scaler.transform(features.values)\n",
    "\n",
    "    df[col_names] = features\n",
    "\n",
    "    return df\n",
    "\n",
    "col_names = ['amt']\n",
    "\n",
    "X_train = Standard_Scaler (X_train, col_names)\n",
    "\n",
    "X_test = Standard_Scaler (X_test, col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Baseline Model (no imbalance resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll start with building a baseline random forest model so we can have a reference in how the model performs if we left the data as is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Instantiating the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:24.759208Z",
     "start_time": "2024-12-12T21:25:24.757355Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:45.625780Z",
     "start_time": "2024-12-12T21:25:24.759859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "y_pred_baseline = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 Performance and Accuracy Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:45.642199Z",
     "start_time": "2024-12-12T21:25:45.626557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Performance with imbalanced dataset:\")\n",
    "print(classification_report(y_test, y_pred_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:45.659936Z",
     "start_time": "2024-12-12T21:25:45.643238Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred_baseline)\n\u001b[0;32m      3\u001b[0m rf_baseline_Recall \u001b[38;5;241m=\u001b[39m recall_score(y_test, y_pred_baseline)\n\u001b[0;32m      4\u001b[0m rf_baseline_Precision \u001b[38;5;241m=\u001b[39m precision_score(y_test, y_pred_baseline)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_baseline)\n",
    "\n",
    "rf_baseline_Recall = recall_score(y_test, y_pred_baseline)\n",
    "rf_baseline_Precision = precision_score(y_test, y_pred_baseline)\n",
    "rf_baseline_f1 = f1_score(y_test, y_pred_baseline)\n",
    "rf_baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
    "\n",
    "ndf = [(rf_baseline_Recall, rf_baseline_Precision, rf_baseline_f1, rf_baseline_accuracy)]\n",
    "\n",
    "rf_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
    "rf_score.insert(0, 'Random Forest performed with', 'Original (Imbalanced Dataset)')\n",
    "rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Random Resampling Methods for Imbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Random Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 Instantiating the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:25:45.766852Z",
     "start_time": "2024-12-12T21:25:45.660599Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# defining oversampling method\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "rf_oversample = RandomForestClassifier(n_estimators=200)\n",
    "X_train_oversample, y_train_oversample = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:15.341971Z",
     "start_time": "2024-12-12T21:25:45.767677Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_oversample.fit(X_train_oversample, y_train_oversample)\n",
    "y_pred_oversample = rf_oversample.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 Performance and Accuracy Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:15.356519Z",
     "start_time": "2024-12-12T21:26:15.343009Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Performance with Random Oversampling:\")\n",
    "print(classification_report(y_test, y_pred_oversample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:15.375293Z",
     "start_time": "2024-12-12T21:26:15.357072Z"
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_oversample)\n",
    "\n",
    "oversample_rf_Recall = recall_score(y_test, y_pred_oversample)\n",
    "oversample_rf_Precision = precision_score(y_test, y_pred_oversample)\n",
    "oversample_rf_f1 = f1_score(y_test, y_pred_oversample)\n",
    "oversample_rf_accuracy = accuracy_score(y_test, y_pred_oversample)\n",
    "\n",
    "ndf_over = [(oversample_rf_Recall, oversample_rf_Precision, oversample_rf_f1, oversample_rf_accuracy)]\n",
    "\n",
    "oversample_rf_score = pd.DataFrame(data = ndf_over, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
    "oversample_rf_score.insert(0, 'Random Forest performed with', 'Random Oversampling')\n",
    "oversample_rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Random Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Instantiate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:15.388770Z",
     "start_time": "2024-12-12T21:26:15.375981Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# defining oversampling method\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "rf_undersample = RandomForestClassifier(n_estimators=200)\n",
    "X_train_undersample, y_train_undersample = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:16.154974Z",
     "start_time": "2024-12-12T21:26:15.389708Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rf_undersample.fit(X_train_undersample, y_train_undersample)\n",
    "y_pred_undersample = rf_undersample.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 Performance and Accuracy Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:16.176689Z",
     "start_time": "2024-12-12T21:26:16.156531Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Performance with Random Undersampling:\")\n",
    "print(classification_report(y_test, y_pred_undersample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:16.194189Z",
     "start_time": "2024-12-12T21:26:16.177363Z"
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_undersample)\n",
    "\n",
    "undersample_rf_Recall = recall_score(y_test, y_pred_undersample)\n",
    "undersample_rf_Precision = precision_score(y_test, y_pred_undersample)\n",
    "undersample_rf_f1 = f1_score(y_test, y_pred_undersample)\n",
    "undersample_rf_accuracy = accuracy_score(y_test, y_pred_undersample)\n",
    "\n",
    "ndf_over = [(undersample_rf_Recall, undersample_rf_Precision, undersample_rf_f1, undersample_rf_accuracy)]\n",
    "\n",
    "undersample_rf_score = pd.DataFrame(data = ndf_over, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
    "undersample_rf_score.insert(0, 'Random Forest performed with', 'Random Undersampling')\n",
    "undersample_rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 SMOTE (Synthetic Minority Oversampling Technique)Â¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 Instantiate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:16.341942Z",
     "start_time": "2024-12-12T21:26:16.194916Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "rf_smote = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:26.757324Z",
     "start_time": "2024-12-12T21:26:16.343287Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_smote.fit(X_train_smote,y_train_smote)\n",
    "y_pred_smote = rf_smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.3 Performance and Accuracy Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:26.773978Z",
     "start_time": "2024-12-12T21:26:26.761239Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Performance with SMOTE:\")\n",
    "print(classification_report(y_test, y_pred_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:26.788407Z",
     "start_time": "2024-12-12T21:26:26.774566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cm_smote = confusion_matrix(y_test, y_pred_smote)\n",
    "rf_smote_Recall = recall_score(y_test, y_pred_smote)\n",
    "rf_smote_Precision = precision_score(y_test, y_pred_smote)\n",
    "rf_smote_f1 = f1_score(y_test, y_pred_smote)\n",
    "rf_smote_accuracy = accuracy_score(y_test, y_pred_smote)\n",
    "\n",
    "ndf = [(rf_smote_Recall, rf_smote_Precision, rf_smote_f1, rf_smote_accuracy)]\n",
    "\n",
    "rf_smote_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
    "rf_smote_score.insert(0, 'Random Forest performed with', 'Smote Oversampling')\n",
    "rf_smote_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Tomek & SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1 Instantiate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:26:49.009287Z",
     "start_time": "2024-12-12T21:26:26.789055Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "SMOTETomek = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'))\n",
    "rf_SMOTETomek = RandomForestClassifier(n_estimators=200)\n",
    "X_train_SMOTETomek, y_train_SMOTETomek = SMOTETomek.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.2 Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:27:54.829740Z",
     "start_time": "2024-12-12T21:26:49.010040Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_SMOTETomek.fit(X_train_SMOTETomek,y_train_SMOTETomek)\n",
    "y_pred_SMOTETomek = rf_SMOTETomek.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.3 Performance and Accuracy Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:27:54.843264Z",
     "start_time": "2024-12-12T21:27:54.830616Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Performance with SMOTE:\")\n",
    "print(classification_report(y_test, y_pred_SMOTETomek))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:27:54.857897Z",
     "start_time": "2024-12-12T21:27:54.843838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cm_smote_tomek = confusion_matrix(y_test, y_pred_SMOTETomek)\n",
    "rf_smote_tomek_Recall = recall_score(y_test, y_pred_SMOTETomek)\n",
    "rf_smote_tomek_Precision = precision_score(y_test, y_pred_SMOTETomek)\n",
    "rf_smote_tomek_f1 = f1_score(y_test, y_pred_SMOTETomek)\n",
    "rf_smote_tomek_accuracy = accuracy_score(y_test, y_pred_SMOTETomek)\n",
    "\n",
    "ndf = [(rf_smote_tomek_Recall, rf_smote_tomek_Precision, rf_smote_tomek_f1, rf_smote_tomek_accuracy)]\n",
    "\n",
    "rf_smote_tomek_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
    "rf_smote_tomek_score.insert(0, 'Random Forest performed with', 'SMOTE & Tomek')\n",
    "rf_smote_tomek_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:27:54.861953Z",
     "start_time": "2024-12-12T21:27:54.858452Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rf_sampling_scores = pd.concat([rf_score, oversample_rf_score, undersample_rf_score,rf_smote_score, rf_smote_tomek_score],axis = 0)\n",
    "rf_sampling_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Applying best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.1 Showing the accuracy score again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:27:54.865136Z",
     "start_time": "2024-12-12T21:27:54.862508Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_undersample)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.2 Print the predicted and actual class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T21:27:54.873951Z",
     "start_time": "2024-12-12T21:27:54.865686Z"
    }
   },
   "outputs": [],
   "source": [
    "# remapping the classes \n",
    "class_names = {1:'Fraud',0:'No Fraud'}\n",
    "predicted_classes = [class_names[label] for label in y_pred_undersample]\n",
    "\n",
    "# Mapping true labels to custom class names\n",
    "class_map = [class_names[label] for label in y_test]\n",
    "\n",
    "# Step 10: Print the predicted and actual class names for the first 5 test samples\n",
    "for i in range(20):\n",
    "    print(f\"Sample {i+1}: True Class: {class_map[i]}, Predicted Class: {predicted_classes[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 817870,
     "sourceId": 1399887,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30806,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
